{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NumPy\n",
    "## NumPy Indexing and Selection\n",
    "\n",
    "Discussion how to select elements or groups of elements from an array.\n",
    "\n",
    "## Bracket Indexing and Selection\n",
    "The simplest way to pick one or some elements of an array looks very similar to python lists:\n",
    "* `arr[8]` \n",
    "* `arr[0:5]`\n",
    "\n",
    "## Broadcasting\n",
    "Numpy arrays differ from a normal Python list because of their ability to broadcast:\n",
    "\n",
    "* `arr[0:5]=100` Setting a value with index range (Broadcasting)\n",
    "\n",
    "* `slice_of_arr = arr[0:6]` Important notes on Slices\n",
    "\n",
    "* `slice_of_arr[:]=99` Change Slice --> !!! Now note the changes also occur in our original array!\n",
    "\n",
    "Data is not copied, it's a view of the original array! This avoids memory problems!\n",
    "* `arr_copy = arr.copy()` To get a copy, need to be explicit\n",
    "\n",
    "## Indexing a 2D array (matrices)\n",
    "The general format is **arr_2d[row][col]** or **arr_2d[row,col]**. I recommend usually using the comma notation for clarity.\n",
    "\n",
    "Generate array manually\n",
    "* `arr_2d = np.array(([5,10,15],[20,25,30],[35,40,45]))`\n",
    "* `arr_2d = np.random.randint(50, size=(5,10)); arr_2d` !!!randint doesnt has reshape\n",
    "* `arr_2d[1]` or `arr_2d[1][0]`\n",
    "\n",
    "2D array slicing\n",
    "* `arr_2d[:2,1:]`\n",
    "\n",
    "### Fancy Indexing\n",
    "Fancy indexing allows you to select entire rows or columns out of order,to show this, let's quickly build out a numpy array:\n",
    "\n",
    "* `arr2d = np.zeros((10,10))`\n",
    "* `arr_length = arr2d.shape[1] `\n",
    "* `for i in range(arr_length):arr2d[i] = i; arr2d` Set up array\n",
    "* `arr2d[[2,4,6,8]]` or `arr2d[[6,4,2,7]]` in any order\n",
    "\n",
    "## Selection\n",
    "Let's briefly go over how to use brackets for selection based off of comparison operators.\n",
    "\n",
    "* `x = 2; arr[arr>x]` using booleans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Operations\n",
    "## Arithmetic\n",
    "You can easily perform array with array arithmetic, or scalar with array arithmetic. Let's see some examples:\n",
    "\n",
    "* `arr + arr`\n",
    "* `arr * arr`\n",
    "* `arr - arr`\n",
    "* `arr/arr`\n",
    "* `1/arr`\n",
    "* `arr**3`\n",
    "\n",
    "## Universal Array Functions\n",
    "Numpy comes with many [universal array functions](http://docs.scipy.org/doc/numpy/reference/ufuncs.html), which are essentially just mathematical operations you can use to perform the operation across the array. Let's show some common ones:\n",
    "\n",
    "* `np.sqrt(arr)`\n",
    "* `np.exp(arr)`\n",
    "* `np.max(arr) #same as arr.max()`\n",
    "* `np.sin(arr)`\n",
    "* `np.log(arr)`\n",
    "* `mat.sum()`\n",
    "* `mat.std()`\n",
    "\n",
    "Get the sum of all the columns in mat\n",
    "* `mat.sum(axis=0)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Series --> very flexible : A pandas Series can hold a variety of object types\n",
    "The first main data type we will learn about for pandas is the Series data type. Let's import Pandas and explore the Series object.\n",
    "\n",
    "A Series is very similar to a NumPy array (in fact it is built on top of the NumPy array object). What differentiates the NumPy array from a Series, is that a Series can have axis labels, meaning it can be indexed by a label, instead of just a number location. It also doesn't need to hold numeric data, it can hold any arbitrary Python Object.\n",
    "\n",
    "* `labels = ['a','b','c']`\n",
    "* `my_list = [10,20,30]`\n",
    "* `arr = np.array([10,20,30])`\n",
    "* `d = {'a':10,'b':20,'c':30}`\n",
    "\n",
    "Using __list__\n",
    "* `pd.Series(data=my_list, index=labels)`\n",
    "\n",
    "Using __NumPy arrays__\n",
    "* `pd.Series(arr, labels)`\n",
    "\n",
    "Using __dictionary__\n",
    "* `pd.Series(d)`\n",
    "\n",
    "Even __functions__ (although unlikely that you will use this)\n",
    "* `pd.Series([sum,print,len])`\n",
    "\n",
    "## Using an Index\n",
    "\n",
    "The key to using a Series is understanding its index. Pandas makes use of these index names or numbers by allowing for fast look ups of information (works like a hash table or dictionary).\n",
    "\n",
    "* `ser1 = pd.Series([1,2,3,4],index = ['USA', 'Germany','USSR', 'Japan'])`\n",
    "* `ser2 = pd.Series([1,2,5,4],index = ['USA', 'Germany','Italy', 'Japan'])`\n",
    "\n",
    "Operations are then also done based off of index (based on index):\n",
    "* `ser1['USA]`\n",
    "* `ser1.keys()`\n",
    "* `ser1 + ser2` !! Pandas and numpy will try to always convert INTEGERS into FLOATS in order to not loose information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataFrames\n",
    "DataFrames are the workhorse of pandas and are directly inspired by the R programming language. We can think of a DataFrame as a bunch of Series objects put together to share the same index. Let's use pandas to explore this topic!\n",
    "\n",
    "* `import pandas as pd`\n",
    "* `import numpy as np`\n",
    "* `from numpy.random import randn`\n",
    "* `np.random.seed(101)`\n",
    "* `df = pd.DataFrame(randn(5,4),index='A B C D E'.split(),columns='W X Y Z'.split())`\n",
    "\n",
    "## Selection and Indexing\n",
    "Let's learn the various methods to grab data from a DataFrame\n",
    "* `df['W']`\n",
    "* `type(df['W'])` pandas.core.series.Series !!DataFrame Columns are just Series\n",
    "* `type(df)` pandas.core.frame.DataFrame\n",
    "* `df[['W','Z']]` Pass a list of column names\n",
    "\n",
    "__Creating a new column:__\n",
    "* `df['new'] = df['W'] + df['Y']`\n",
    "\n",
    "__Removing Columns__\n",
    "* `df.drop('new',axis=1)`\n",
    "\n",
    "__Not inplace unless specified!__\n",
    "* `df.drop('new',axis=1,inplace=True)`\n",
    "\n",
    "__Can also drop rows this way:__\n",
    "* `df.drop('E',axis=0)`\n",
    "\n",
    "__Selecting Rows__\n",
    "* `df.loc['A']`\n",
    "\n",
    "__Or select based off of position instead of label__\n",
    "* `df.iloc[2]`\n",
    "\n",
    "__Selecting subset of rows and columns__\n",
    "* `df.loc['B','Y']`\n",
    "* `df.loc[['A','B'],['W','Y']]` list of columns and rows __[['',''],['','']]__\n",
    "\n",
    "### Conditional Selection\n",
    "An important feature of pandas is conditional selection using bracket notation, very similar to numpy:\n",
    "\n",
    "* `df>0`\n",
    "* `df[df>0]`\n",
    "* `df[df['W']>0]` returns only rows or columns for which the condition is true.\n",
    "* `df[df['Z']<0][['X', 'Y']]`\n",
    "\n",
    "example:\n",
    "* `boolser = df['W']>0`\n",
    "* `result = df[boolser]`\n",
    "* `my_cols = ['Y','X']`\n",
    "* `result[my_cols]`\n",
    "\n",
    "__Multiple conditions__\n",
    "!! AND operator gets confused :not series of boolean values but single boolean values (True, False)\n",
    "* `df[(df['W']>0) and (df['Y']>1)]` !!! NOT\n",
    "* `df[(df['W']>0) & (df['Y']>1)]` !!! OK\n",
    "\n",
    "### Reseting the index or setting it to something else\n",
    "** Reset to default 0,1...n index\n",
    "\n",
    "* `df.reset_index()`\n",
    "* `newind = 'CA NY WY OR CO'.split()`\n",
    "* `df['States'] = newind`\n",
    "* `df.set_index('States')` or `df.set_index('States',inplace=True)`\n",
    "\n",
    "### Multi-Index and Index Hierarchy\n",
    "Let us go over how to work with Multi-Index, first we'll create a quick example of what a Multi-Indexed DataFrame would look like:\n",
    "\n",
    "Index Levels\n",
    "* `outside = ['G1','G1','G1','G2','G2','G2']`\n",
    "* `inside = [1,2,3,1,2,3]`\n",
    "* `hier_index = list(zip(outside,inside))`\n",
    "* `hier_index = pd.MultiIndex.from_tuples(hier_index)`\n",
    "* `df = pd.DataFrame(np.random.randn(6,2),index=hier_index,columns=['A','B'])`\n",
    "\n",
    "Now let's show how to index this! For index hierarchy we use df.loc[], if this was on the columns axis, you would just use normal bracket notation df[]. Calling one level of the index returns the sub-dataframe:\n",
    "\n",
    "* `df.loc['G1']`\n",
    "* `df.loc['G1'].loc[1]`\n",
    "* `df.index.names` none\n",
    "* `df.index.names = ['Group','Num']`\n",
    "* `df.xs('G1')` returns a cross section of row/s or column/s from the series/dataframes. Used in multilevel index\n",
    "* `df.xs(['G1',1])`\n",
    "* `df.xs(1,level='Num')` allows to grab cross section levels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing Data\n",
    "Let's show a few convenient methods to deal with Missing Data in pandas:\n",
    "\n",
    "* `df = pd.DataFrame({'A':[1,2,np.nan],'B':[5,np.nan,np.nan],'C':[1,2,3]})`\n",
    "* `df.dropna()` by default axis=0 the operation occurs allong the rows; axis=1 for columns\n",
    "* `df.dropna(thresh=2)` to keep >2 non null values \n",
    "* `df.fillna(value='FILL VALUE')`\n",
    "* `df['A'].fillna(value=df['A'].mean())`\n",
    "\n",
    "# Groupby\n",
    "The groupby method allows you to group rows of data together and call aggregate functions\n",
    "import pandas as pd\n",
    "\n",
    "** Create dataframe**\n",
    "* `data = {'Company':['GOOG','GOOG','MSFT','MSFT','FB','FB'],`\n",
    "          `'Person' :['Sam','Charlie','Amy','Vanessa','Carl','Sarah'],`\n",
    "          `'Sales'  :[200,120,340,124,243,350]}`\n",
    "* `df = pd.DataFrame(data)`\n",
    "** Now you can use the .groupby() method to group rows together based off of a column name. For instance let's group based off of Company. This will create a DataFrameGroupBy object:**\n",
    "\n",
    "* `df.groupby('Company')`\n",
    "\n",
    "You can save this object as a new variable:\n",
    "* `by_comp = df.groupby('Company')`\n",
    "In one line:\n",
    "* `df.groupby('Company').sum().loc['FB']` group by company and aggregate by sales just for FB\n",
    "\n",
    "And then call aggregate methods off the object:\n",
    "* `by_comp.mean()` or `by_comp.std()` or `by_comp.min()` or `by_comp.max()`\n",
    "* `df.groupby('Company').count()` count the number of istances\n",
    "* `by_comp.describe()` information all in once\n",
    "* `by_comp.describe().transpose()`\n",
    "* `by_comp.describe().transpose()['GOOG']`\n",
    "\n",
    "# Merging, Joining, and Concatenating\n",
    "There are 3 main ways of combining DataFrames together: Merging, Joining and Concatenating. In this lecture we will discuss these 3 methods with examples.\n",
    "\n",
    "`df1 = pd.DataFrame({'A': ['A0', 'A1', 'A2', 'A3'],`\n",
    "                        `'B': ['B0', 'B1', 'B2', 'B3'],`\n",
    "                        `'C': ['C0', 'C1', 'C2', 'C3'],`\n",
    "                        `'D': ['D0', 'D1', 'D2', 'D3']},`\n",
    "                        `index=[0, 1, 2, 3])`\n",
    "                        \n",
    "`df2 = pd.DataFrame({'A': ['A4', 'A5', 'A6', 'A7'],`\n",
    "                        `'B': ['B4', 'B5', 'B6', 'B7'],`\n",
    "                        `'C': ['C4', 'C5', 'C6', 'C7'],`\n",
    "                        `'D': ['D4', 'D5', 'D6', 'D7']},`\n",
    "                        ` index=[4, 5, 6, 7]) `\n",
    "                         \n",
    "`df3 = pd.DataFrame({'A': ['A8', 'A9', 'A10', 'A11'],`\n",
    "                        `'B': ['B8', 'B9', 'B10', 'B11'],`\n",
    "                        `'C': ['C8', 'C9', 'C10', 'C11'],`\n",
    "                        `'D': ['D8', 'D9', 'D10', 'D11']},`\n",
    "                        `index=[8, 9, 10, 11])`\n",
    "                        \n",
    "## Concatenation\n",
    "Concatenation basically glues together DataFrames. Keep in mind that dimensions should match along the axis you are concatenating on. You can use **pd.concat** and pass in a list of DataFrames to concatenate together:\n",
    "\n",
    "* `pd.concat([df1,df2,df3])` (axis=0 by rows)\n",
    "* `pd.concat([df1,df2,df3],axis=1)` (axis=1 by columns)\n",
    "\n",
    "## Merging\n",
    "\n",
    "`left = pd.DataFrame({'key': ['K0', 'K1', 'K2', 'K3'],`\n",
    "                     `'A': ['A0', 'A1', 'A2', 'A3'],`\n",
    "                     `'B': ['B0', 'B1', 'B2', 'B3']})`\n",
    "   \n",
    "`right = pd.DataFrame({'key': ['K0', 'K1', 'K2', 'K3'],`\n",
    "                          `'C': ['C0', 'C1', 'C2', 'C3'],`\n",
    "                          `'D': ['D0', 'D1', 'D2', 'D3']})`\n",
    "\n",
    "The **merge** function allows you to merge DataFrames together using a similar logic as merging SQL Tables together. For example:\n",
    "\n",
    "* `pd.merge(left,right,how='inner',on='key')` or\n",
    "* `pd.merge(left, right, on=['key1', 'key2'])` with 2 keys\n",
    "* `pd.merge(left, right, how='outer', on=['key1', 'key2'])`\n",
    "* `pd.merge(left, right, how='right', on=['key1', 'key2'])`\n",
    "* `pd.merge(left, right, how='left', on=['key1', 'key2'])`\n",
    "\n",
    "## Joining\n",
    "Joining is a convenient method for combining the columns of two potentially differently-indexed DataFrames into a single result DataFrame.\n",
    "\n",
    "`left = pd.DataFrame({'A': ['A0', 'A1', 'A2'],`\n",
    "                     `'B': ['B0', 'B1', 'B2']},`\n",
    "                      `index=['K0', 'K1', 'K2']) `\n",
    "\n",
    "`right = pd.DataFrame({'C': ['C0', 'C2', 'C3'],`\n",
    "                    `'D': ['D0', 'D2', 'D3']},`\n",
    "                      `index=['K0', 'K2', 'K3'])`\n",
    "* `left.join(right)`\n",
    "* `left.join(right, how='outer')`\n",
    "\n",
    "# Operations\n",
    "There are lots of operations with pandas that will be really useful to you, but don't fall into any distinct category. Let's show them here in this lecture:\n",
    "\n",
    "* `df = pd.DataFrame({'col1':[1,2,3,4],'col2':[444,555,666,444],'col3':['abc','def','ghi','xyz']})`\n",
    "\n",
    "## Info on Unique Values\n",
    "\n",
    "* `df['col2'].unique()` return a numpy array with all the unique values of numpy array\n",
    "* `len(df['col2'].unique())` return the number of unique values same as __nunique__\n",
    "* `df['col2'].nunique()`\n",
    "* `df['col2'].value_counts()` how many times unique values show up\n",
    "\n",
    "## Selecting Data\n",
    "Select from DataFrame using criteria from multiple columns\n",
    "\n",
    "* `newdf = df[(df['col1']>2) & (df['col2']==444)]` conditional selection\n",
    "* `def`__times2__`(x):return x*2`\n",
    "* `df['col1'].apply(`__times2__`)` broadcast the fucntion to each element in the column\n",
    "* `df['col3'].apply(len)` apply the lengh of each string in col3\n",
    "* `df['col2'].apply(lambda x: x*2)`\n",
    "* `df['col1'].sum()`\n",
    "* `df.drop('col1', axis=1, implace=True)`\n",
    "\n",
    "** Permanently Removing a Column**\n",
    "* `del df['col1']`\n",
    "\n",
    "** Get column and index names: **\n",
    "* `df.columns`list object with column names\n",
    "* `df.index` list object with row/index names\n",
    "\n",
    "** Sorting and Ordering a DataFrame:**\n",
    "* `df.`__sort_values__`(by='col2') #inplace=False by default`\n",
    "\n",
    "** Find Null Values or Check for Null Values**\n",
    "* `df.isnull()` boolean of values if they were null or not\n",
    "** Filling in NaN values with something else: **\n",
    "* `df.fillna('FILL')`\n",
    "\n",
    "`df = pd.DataFrame({'col1':[1,2,3,np.nan],`\n",
    "                   `'col2':[np.nan,555,666,444],`\n",
    "                   `'col3':['abc','def','ghi','xyz']})`\n",
    "!!! repetead values in each column\n",
    "we are going to use muòlti level-index\n",
    "\n",
    "* `df.pivot_table(values='D',index=['A', 'B'],columns=['C'])` we want the data points be sorted by column D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Input and Output\n",
    "This notebook is the reference code for getting input and output, pandas can read a variety of file types using its pd.read_ methods. Let's take a look at the most common data types:\n",
    "\n",
    "__reading__\n",
    "* `df = pd.read_csv('example')` use tab for autocomplete file name\n",
    "\n",
    "__writing__\n",
    "* `df.to_csv('example',index=False)`\n",
    "\n",
    "## Excel\n",
    "Pandas can read and write excel files, keep in mind, this only imports data. Not formulas or images, having images or macros may cause this read_excel method to crash. \n",
    "\n",
    "__reading__\n",
    "* `pd.read_excel('Excel_Sample.xlsx',sheet_name='Sheet1')`\n",
    "\n",
    "__writing__\n",
    "* `df.to_excel('Excel_Sample.xlsx',sheet_name='Sheet1')`\n",
    "\n",
    "## HTML\n",
    "You may need to install htmllib5,lxml, and BeautifulSoup4. In your terminal/command prompt run:\n",
    "\n",
    "    conda install lxml\n",
    "    conda install html5lib\n",
    "    conda install BeautifulSoup4\n",
    "\n",
    "Then restart Jupyter Notebook.\n",
    "(or use pip install if you aren't using the Anaconda Distribution)\n",
    "Pandas can read table tabs off of html. For example:\n",
    "\n",
    "### HTML Input\n",
    "Pandas read_html function will read tables off of a webpage and return a list of DataFrame objects:\n",
    "* `df = pd.read_html('http://www.fdic.gov/bank/individual/failed/banklist.html')`\n",
    "* `df[0]`\n",
    "\n",
    "# SQL (Optional)\n",
    "\n",
    "* Note: If you are completely unfamiliar with SQL you can check out my other course: \"Complete SQL Bootcamp\" to learn SQL.\n",
    "The pandas.io.sql module provides a collection of query wrappers to both facilitate data retrieval and to reduce dependency on DB-specific API. Database abstraction is provided by SQLAlchemy if installed. In addition you will need a driver library for your database. Examples of such drivers are psycopg2 for PostgreSQL or pymysql for MySQL. For SQLite this is included in Python’s standard library by default. You can find an overview of supported drivers for each SQL dialect in the SQLAlchemy docs.\n",
    "\n",
    "If SQLAlchemy is not installed, a fallback is only provided for sqlite (and for mysql for backwards compatibility, but this is deprecated and will be removed in a future version). This mode requires a Python database adapter which respect the Python DB-API.\n",
    "See also some cookbook examples for some advanced strategies.\n",
    "The key functions are:\n",
    "\n",
    "* read_sql_table(table_name, con[, schema, ...])\t\n",
    "    * Read SQL database table into a DataFrame.\n",
    "* read_sql_query(sql, con[, index_col, ...])\t\n",
    "    * Read SQL query into a DataFrame.\n",
    "* read_sql(sql, con[, index_col, ...])\t\n",
    "    * Read SQL query or database table into a DataFrame.\n",
    "* DataFrame.to_sql(name, con[, flavor, ...])\t\n",
    "    * Write records stored in a DataFrame to a SQL database.\n",
    "\n",
    "* `from sqlalchemy import create_engine`\n",
    "* `engine = create_engine('sqlite:///:memory:')`\n",
    "\n",
    "** remember to reset df\n",
    "* `df.to_sql('data', con=engine)`\n",
    "* `sql_df = pd.read_sql('data',con=engine)`\n",
    "* `sql_df`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
